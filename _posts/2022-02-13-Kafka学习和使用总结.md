---
layout: post
title:  "Kafka学习和使用总结"
date:   2022-02-13 10:00:00 -0000
categories: 技术
tags:  
---

最近项目中在使用Kafka，看了[Kafka: The Definitive Guide v2](https://www.oreilly.com/library/view/kafka-the-definitive/9781492043072/), 也看了一些博客。这篇不打算写一个详细的介绍，写一写我认为比较核心的东西。

Kafka是一个分布式的log系统。性能和扩展性很好，也能一定时间内持久化信息。

## 性能
### Partition
Kafka 基于partition来实现并发，想当于数据的[sharding](https://www.investopedia.com/terms/s/sharding.asp#:~:text=Sharding%20is%20a%20database%20partitioning,process%20more%20transactions%20per%20second.&text=Sharding%20can%20help%20reduce%20the,blockchain%20network%20into%20separate%20shards.)， 是一个比较普遍的概念. 不同的partition是独立的，不同partition的数据可以并发的进行处理。每个partition都是一个有序的log列表。

### 数据结构
message 即log，append-only，不会对数据做什么处理，读写都很简单。也因为不处理信息，也让压缩消息更简单。

### Cache
利用OS的cache，因为log性质，读绝大多数的时候都是顺序读log文件，天然的locality；写的时候也只是写到cache，利用操作系统的flush来写到disk。第二是append-only，没有cache consistent等复杂的需求。还有一个非常重要的优化就是Kafka 读消息的时候，可以绕过OS kernel，从cache直接copy数据到NIC。

### Batch
这个概念也很常见，为了减少internet交互的次数，在produce 和 consume 的时候可以打包很多message。跟这个有些相关的是Kafka支持压缩消息，减少网络带宽的利用。

## 可靠性
### replicas
可靠性基本是靠replicas来实现的。前面提到Kafka写只是写到cache，依靠OS来写到内存，所以是存在机器down掉但message还没写到disk的问题。Kafka解决这个问题的办法是同时写到多个replicas，假设多个机器不会同时down掉，这也是很多内存数据库的解决办法。

由replicas带来的问题就是不同replicas可能数据不一致的问题。解决办法是replicas之间指定一个leader（基于zookeeper来保证leader的唯一性，Kafka 3.0 会用Raft来选举leader），每一个partition都有一个leader，leader接受所有的write请求，然后负责replicate到各个replica。取决于应用的需求，可以配置写请求replicate到多少个replica算是commit。consumer只能读commited的消息。

leader down掉的情况有点复杂，大致解决办法是重新从followers中重新选择一个leader，但是这个follower 必须是sync-up的，sync-up的意思是在一定时间内他和leader有通信，我们假定他和leader有同样的commited log（并不一定对，取决于commit number的配置）。因为leader可能有未commit的log，然后挂掉，所以Kafka的log是不连续的。

如果没有配置，kafka是可能有重复的消息的，Kafka 也支持[**exactly-once semantics**](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/) ，每条消息会assign一个unique number, 然后检测这个unique number是否在最近几条log总存在（因为最多检查最近5条log，理论是应该还是会出现重复的情况的）

## 储存
Kafka的log文件叫segment，当log写到超过1GB，会创建一个新的segment。Kafka会设置retention time，当segment超过一定时间，就会被删掉。（当前的segment不会被删，但是过期数据不能被读到的）。

除了log文件，Kafka还有两个额外的index文件，其中一个是offset（快速的读取某一个offset），还有一个是timestamp（比如过期数据的处理就会依赖timestamp的index）。

在3.0之后Kafka引入了分级的储存，可以支持把log文件存到HDFS或S3，这样kafka就能支持更长时间的存储数据，可以用作一个event的数据库。

## 项目中遇到的坑

在项目遇到的一个坑是多个producer，asyncSend是没办法保证消息的顺序的。即使produce配置只用一个线程来发送消息。这个会造成系统在外部看来不是线性的，比如说如下的系统：
1. user A 发送一个请求： set x = 1 
2. 应用接收到请求，发送到kafka，由下一级系统来处理。aysncSend（x = 1）
3. user A 又发送一个请求： set x = 2
4. 服务存在多个节点，请求被转发到另一台机器。aysncSend（x = 2）
5. 最终message的顺序可能是 (x = 2)， (x = 1)
我们系统是用一个[ACID](https://en.wikipedia.org/wiki/ACID)的数据库来保证事件的顺序，然后Kafka转播这些事件，各个consumer实现检查和保证顺序的功能。

